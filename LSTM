import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import optuna

# Load the dataset
df = pd.read_csv('path/to/your/bitcoin_data.csv')  # Update the path as needed
df['Date'] = pd.to_datetime(df['Date'])
data = df[['y']].values  # Target variable

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Function to create sequences for LSTM
def create_sequences(data, sequence_length):
    X, y = [], []
    for i in range(sequence_length, len(data)):
        X.append(data[i-sequence_length:i])
        y.append(data[i])
    return np.array(X), np.array(y)

# Objective function for Optuna
def objective(trial):
    sequence_length = trial.suggest_int('sequence_length', 30, 120)
    lstm_units = trial.suggest_int('lstm_units', 32, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    batch_size = trial.suggest_int('batch_size', 16, 64)
    epochs = trial.suggest_int('epochs', 10, 50)

# Create sequences
sequence_length = 60  # Lookback window

    # Train
    X_train, y_train = X[:-14], y[:-14]  # Leave last 14 for testing
    X_test, y_test = X[-14:], y[-14:]

    # Reshape for LSTM
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

    # Build the model
    model = Sequential([
	LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
	LSTM(units=50),
	Dense(units=14)  # Outputting 14 future days
])
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    # Train the model
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    # Make predictions
    predicted = model.predict(X_test)
    predicted = scaler.inverse_transform(predicted)

    # Calculate RMSE
    actual = scaler.inverse_transform(y_test.reshape(-1, 1))
    rmse = np.sqrt(mean_squared_error(actual_values, predicted[:14]))
    print("RMSE:", rmse)

# Create and run the Optuna study
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=30)

# Print the best hyperparameters
best_params = study.best_params
print("Best hyperparameters:", best_params)
print("Best RMSE:", study.best_value)

# Using the best parameters to train the final model
sequence_length = best_params['sequence_length']
lstm_units = best_params['lstm_units']
dropout_rate = best_params['dropout_rate']
batch_size = best_params['batch_size']
epochs = best_params['epochs']

# Create sequences with best parameters
X, y = create_sequences(data_scaled, sequence_length)
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Train on the entire dataset
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(units=lstm_units, return_sequences=True, input_shape=(X.shape[1], 1)),
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.LSTM(units=lstm_units // 2),
    tf.keras.layers.Dropout(dropout_rate),
    tf.keras.layers.Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X, y, epochs=epochs, batch_size=batch_size)

# Make a 14-day forecast
last_sequence = data_scaled[-sequence_length:]
last_sequence = np.reshape(last_sequence, (1, sequence_length, 1))

# Predict the next values
predicted_scaled = []
for _ in range(14):  # Predicting 14 days
    prediction = model.predict(last_sequence)
    predicted_scaled.append(prediction[0, 0])  # Append the predicted value
    last_sequence = np.append(last_sequence[:, 1:, :], [[prediction]], axis=1)  # Update last_sequence

# Inverse transform the predicted values
predicted = scaler.inverse_transform(np.array(predicted_scaled).reshape(-1, 1))

# Generate forecast dates
forecast_dates = pd.date_range(df['Date'].iloc[-1] + pd.Timedelta(days=1), periods=14)
forecast_df = pd.DataFrame({'Date': forecast_dates, 'Predicted': predicted.flatten()})

print(forecast_df)

from sklearn.metrics import mean_squared_error
import numpy as np

# Assuming the last 14 days in the dataset are the actual values to compare
actual_values = df['y'].iloc[-14:].values.reshape(-1, 1)

# Rescale actual values back (if already scaled)
actual_values_rescaled = scaler.inverse_transform(actual_values)

# Calculate RMSE between actual and forecasted values
rmse_optuna = np.sqrt(mean_squared_error(actual_values_rescaled, predicted))

# Create a DataFrame for comparison
comparison_df = pd.DataFrame({
    'Date': forecast_df['Date'],
    'Actual': actual_values_rescaled.flatten(),
    'Predicted': forecast_df['Predicted']
})

print("Forecast vs Actual Comparison:")
print(comparison_df)
print("\nRMSE after Optuna Hyperparameter Tuning:", rmse_optuna)


